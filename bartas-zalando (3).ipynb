{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Labels\n\nEach training and test example is assigned to one of the following labels:\n\n* 0 T-shirt/top\n* 1 Trouser\n* 2 Pullover\n* 3 Dress\n* 4 Coat\n* 5 Sandal\n* 6 Shirt\n* 7 Sneaker\n* 8 Bag\n* 9 Ankle boot"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_predict\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans, DBSCAN\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dtrain = pd.read_csv(\"/kaggle/input/fashionmnist/fashion-mnist_train.csv\")\ndtest = pd.read_csv(\"/kaggle/input/fashionmnist/fashion-mnist_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train shape:\\n\", dtrain.shape)\nprint(\"Test shape:\\n\", dtest.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtrain['label'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(dtrain.iloc[3].values[1:].reshape(28, 28), cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = 'label'\n\nX = dtrain.drop([predict], axis=1)\ny = dtrain[predict]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(X_train.iloc[0].values[0:].reshape(28, 28), cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\nX_train_scaled = sc.fit_transform(X_train)\nX_test_scaled = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PART 1**\n\nModels without scale; raw data."},{"metadata":{},"cell_type":"markdown","source":"1.1. Logisitic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# log_reg = LogisticRegression(max_iter=100000)\n# log_reg.fit(X_train, y_train)\n\n# predictions_logreg = log_reg.predict(X_test)\n\n# class_report_logreg = classification_report(y_test, predictions_logreg)\n# print(\"Log Reg classification report:\\n\", class_report_logreg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To less iterations.\n\nLog Reg classification report:\n               precision    recall  f1-score   support\n\n           0       0.79      0.79      0.79      1783\n           1       0.91      0.95      0.93      1795\n           2       0.75      0.76      0.75      1814\n           3       0.82      0.84      0.83      1822\n           4       0.73      0.76      0.74      1805\n           5       0.91      0.90      0.90      1738\n           6       0.64      0.57      0.60      1846\n           7       0.90      0.91      0.91      1841\n           8       0.91      0.92      0.91      1762\n           9       0.92      0.92      0.92      1794\n\n    accuracy                           0.83     18000\n   macro avg       0.83      0.83      0.83     18000\nweighted avg       0.83      0.83      0.83     18000"},{"metadata":{},"cell_type":"markdown","source":"1.2. KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# knn = KNeighborsClassifier(n_neighbors=7)\n# knn.fit(X_train, y_train)\n\n# predictions_knn = knn.predict(X_test)\n\n# class_report_knn = classification_report(y_test, predictions_knn)\n# print(\"KNN classification report:\\n\", class_report_knn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"KNN classification report:\n               precision    recall  f1-score   support\n\n           0       0.76      0.87      0.81      1783\n           1       0.99      0.96      0.97      1795\n           2       0.73      0.81      0.77      1814\n           3       0.88      0.87      0.88      1822\n           4       0.78      0.76      0.77      1805\n           5       0.99      0.82      0.90      1738\n           6       0.67      0.57      0.62      1846\n           7       0.88      0.96      0.92      1841\n           8       0.98      0.95      0.97      1762\n           9       0.90      0.97      0.93      1794\n\n    accuracy                           0.85     18000\n   macro avg       0.86      0.85      0.85     18000\nweighted avg       0.86      0.85      0.85     18000"},{"metadata":{},"cell_type":"markdown","source":"1.3. SVC"},{"metadata":{"trusted":true},"cell_type":"code","source":"# svc_class = SVC(C=1)\n# svc_class.fit(X_train, y_train)\n\n# predictions_svc = svc_class.predict(X_test)\n\n# class_report_svc = classification_report(y_test, predictions_svc)\n# print(\"SVC classification report:\\n\", class_report_svc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    SVC classification report:\n               precision    recall  f1-score   support\n\n           0       0.81      0.85      0.83      1783\n           1       0.99      0.96      0.98      1795\n           2       0.81      0.83      0.82      1814\n           3       0.86      0.91      0.88      1822\n           4       0.80      0.82      0.81      1805\n           5       0.95      0.95      0.95      1738\n           6       0.74      0.64      0.69      1846\n           7       0.93      0.95      0.94      1841\n           8       0.97      0.98      0.97      1762\n           9       0.97      0.96      0.96      1794\n\n    accuracy                           0.88     18000\n   macro avg       0.88      0.88      0.88     18000\nweighted avg       0.88      0.88      0.88     18000"},{"metadata":{},"cell_type":"markdown","source":"1.4. Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"# rf = RandomForestClassifier(random_state=42)\n# rf.fit(X_train, y_train)\n\n# predictions_rf = rf.predict(X_test)\n\n# class_report_rf = classification_report(y_test, predictions_rf)\n# print(\"Random Forest classification report:\\n\", class_report_rf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest classification report:\n               precision    recall  f1-score   support\n\n           0       0.81      0.86      0.83      1783\n           1       0.99      0.96      0.98      1795\n           2       0.79      0.82      0.80      1814\n           3       0.86      0.91      0.88      1822\n           4       0.76      0.82      0.79      1805\n           5       0.96      0.96      0.96      1738\n           6       0.74      0.57      0.64      1846\n           7       0.94      0.94      0.94      1841\n           8       0.96      0.98      0.97      1762\n           9       0.96      0.96      0.96      1794\n\n    accuracy                           0.88     18000\n   macro avg       0.88      0.88      0.88     18000\nweighted avg       0.88      0.88      0.87     18000"},{"metadata":{},"cell_type":"markdown","source":"****PART 2****\n\nData scaled with Standard Scaler."},{"metadata":{},"cell_type":"markdown","source":"2.1. Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# log_reg = LogisticRegression(max_iter=100000)\n# log_reg.fit(X_train_scaled, y_train)\n\n# predictions_logreg = log_reg.predict(X_test_scaled)\n\n# class_report_logreg = classification_report(y_test, predictions_logreg)\n# print(\"Log Reg scaled classification report:\\n\", class_report_logreg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Log Reg scaled classification report:\n               precision    recall  f1-score   support\n\n           0       0.77      0.79      0.78      1800\n           1       0.95      0.97      0.96      1800\n           2       0.75      0.75      0.75      1800\n           3       0.83      0.84      0.83      1800\n           4       0.75      0.77      0.76      1800\n           5       0.93      0.92      0.93      1800\n           6       0.63      0.58      0.60      1800\n           7       0.91      0.92      0.92      1800\n           8       0.92      0.91      0.92      1800\n           9       0.93      0.93      0.93      1800\n\n    accuracy                           0.84     18000\n   macro avg       0.84      0.84      0.84     18000\nweighted avg       0.84      0.84      0.84     18000"},{"metadata":{},"cell_type":"markdown","source":"2.2. KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# knn = KNeighborsClassifier(n_neighbors=7)\n# knn.fit(X_train_scaled, y_train)\n\n# predictions_knn = knn.predict(X_test_scaled)\n\n# class_report_knn = classification_report(y_test, predictions_knn)\n# print(\"KNN scaled classification report:\\n\", class_report_knn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"KNN scaled classification report:\n               precision    recall  f1-score   support\n\n           0       0.77      0.88      0.82      1800\n           1       0.99      0.96      0.98      1800\n           2       0.76      0.79      0.78      1800\n           3       0.89      0.86      0.87      1800\n           4       0.76      0.77      0.76      1800\n           5       0.99      0.82      0.90      1800\n           6       0.67      0.61      0.64      1800\n           7       0.87      0.96      0.91      1800\n           8       0.98      0.93      0.96      1800\n           9       0.90      0.96      0.93      1800\n\n    accuracy                           0.85     18000\n   macro avg       0.86      0.85      0.85     18000\nweighted avg       0.86      0.85      0.85     18000"},{"metadata":{},"cell_type":"markdown","source":"2.3. SVC"},{"metadata":{"trusted":true},"cell_type":"code","source":"# svc_class = SVC(C=1)\n# svc_class.fit(X_train_scaled, y_train)\n\n# predictions_svc = svc_class.predict(X_test_scaled)\n\n# class_report_svc = classification_report(y_test, predictions_svc)\n# print(\"SVC scaled classification report:\\n\", class_report_svc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SVC scaled classification report:\n               precision    recall  f1-score   support\n\n           0       0.82      0.86      0.84      1800\n           1       0.99      0.97      0.98      1800\n           2       0.82      0.82      0.82      1800\n           3       0.87      0.90      0.89      1800\n           4       0.80      0.84      0.82      1800\n           5       0.97      0.96      0.97      1800\n           6       0.74      0.65      0.69      1800\n           7       0.94      0.95      0.95      1800\n           8       0.95      0.97      0.96      1800\n           9       0.96      0.95      0.95      1800\n\n    accuracy                           0.89     18000\n   macro avg       0.89      0.89      0.89     18000\nweighted avg       0.89      0.89      0.89     18000"},{"metadata":{},"cell_type":"markdown","source":"2.4. Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"# rf = RandomForestClassifier(random_state=42)\n# rf.fit(X_train_scaled, y_train)\n\n# predictions_rf = rf.predict(X_test_scaled)\n\n# class_report_rf = classification_report(y_test, predictions_rf)\n# print(\"Random Forest scaled classification report:\\n\", class_report_rf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest scaled classification report:\n               precision    recall  f1-score   support\n\n           0       0.81      0.86      0.84      1800\n           1       0.99      0.96      0.98      1800\n           2       0.78      0.81      0.80      1800\n           3       0.88      0.91      0.90      1800\n           4       0.76      0.83      0.79      1800\n           5       0.97      0.96      0.96      1800\n           6       0.74      0.59      0.66      1800\n           7       0.94      0.94      0.94      1800\n           8       0.97      0.97      0.97      1800\n           9       0.95      0.95      0.95      1800\n\n    accuracy                           0.88     18000\n   macro avg       0.88      0.88      0.88     18000\nweighted avg       0.88      0.88      0.88     18000"},{"metadata":{},"cell_type":"markdown","source":"**PART 3**\n\nPreprocessing with dimensions reduction by PCA and K-Means with scaled data."},{"metadata":{},"cell_type":"markdown","source":"3.1. PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# n_comps = 0.95\n# pca = PCA(n_components=n_comps)\n# X_train_reduced = pca.fit_transform(X_train_scaled)\n# X_test_reduced = pca.transform(X_test_scaled)\n\n# cumsum = np.cumsum(pca.explained_variance_ratio_)\n# d = np.argmax(cumsum >= n_comps) + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(\"For the deserved ratio of variance {n_comps} the number of principal components is:\\n\", d)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number is 255"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.figure(figsize=(6,4))\n# plt.plot(cumsum, linewidth=3)\n# plt.axis([0, 400, 0, 1])\n# plt.xlabel(\"Dimensions\")\n# plt.ylabel(\"Explained Variance\")\n# plt.plot([d, d], [0, 0.95], \"k:\")\n# plt.plot([0, d], [0.95, 0.95], \"k:\")\n# plt.plot(d, 0.95, \"ko\")\n# plt.annotate(\"Elbow\", xy=(65, 0.85), xytext=(70, 0.7),\n#              arrowprops=dict(arrowstyle=\"->\"), fontsize=16)\n# plt.grid(True)\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=255)\nX_train_reduced = pca.fit_transform(X_train_scaled)\nX_test_reduced = pca.transform(X_test_scaled)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.1.1. Logistic Regression with PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# log_reg = LogisticRegression(max_iter=100000)\n# log_reg.fit(X_train_reduced, y_train)\n\n# predictions_logreg = log_reg.predict(X_test_reduced)\n\n# class_report_logreg = classification_report(y_test, predictions_logreg)\n# print(\"Log Reg reduced classification report:\\n\", class_report_logreg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Log Reg reduced classification report:\n               precision    recall  f1-score   support\n\n           0       0.79      0.81      0.80      1800\n           1       0.97      0.97      0.97      1800\n           2       0.76      0.75      0.76      1800\n           3       0.84      0.87      0.85      1800\n           4       0.74      0.78      0.76      1800\n           5       0.95      0.94      0.94      1800\n           6       0.65      0.59      0.62      1800\n           7       0.92      0.94      0.93      1800\n           8       0.95      0.94      0.94      1800\n           9       0.95      0.94      0.95      1800\n\n    accuracy                           0.85     18000\n   macro avg       0.85      0.85      0.85     18000\nweighted avg       0.85      0.85      0.85     18000"},{"metadata":{},"cell_type":"markdown","source":"3.1.2. KNN with PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# knn = KNeighborsClassifier(n_neighbors=7)\n# knn.fit(X_train_reduced, y_train)\n\n# predictions_knn = knn.predict(X_test_reduced)\n\n# class_report_knn = classification_report(y_test, predictions_knn)\n# print(\"KNN reduced classification report:\\n\", class_report_knn)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"KNN reduced classification report:\n               precision    recall  f1-score   support\n\n           0       0.78      0.87      0.82      1800\n           1       0.99      0.97      0.98      1800\n           2       0.78      0.79      0.78      1800\n           3       0.89      0.87      0.88      1800\n           4       0.75      0.79      0.77      1800\n           5       0.98      0.87      0.92      1800\n           6       0.67      0.61      0.64      1800\n           7       0.90      0.96      0.93      1800\n           8       0.98      0.94      0.96      1800\n           9       0.91      0.96      0.94      1800\n\n    accuracy                           0.86     18000\n   macro avg       0.86      0.86      0.86     18000\nweighted avg       0.86      0.86      0.86     18000"},{"metadata":{},"cell_type":"markdown","source":"3.1.3. SVC with PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# svc_class = SVC(C=1)\n# svc_class.fit(X_train_reduced, y_train)\n\n# predictions_svc = svc_class.predict(X_test_reduced)\n\n# class_report_svc = classification_report(y_test, predictions_svc)\n# print(\"SVC reduced classification report:\\n\", class_report_svc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SVC reduced classification report:\n               precision    recall  f1-score   support\n\n           0       0.82      0.86      0.84      1800\n           1       0.99      0.97      0.98      1800\n           2       0.82      0.81      0.81      1800\n           3       0.87      0.90      0.89      1800\n           4       0.80      0.84      0.82      1800\n           5       0.97      0.96      0.96      1800\n           6       0.74      0.65      0.69      1800\n           7       0.93      0.95      0.94      1800\n           8       0.95      0.97      0.96      1800\n           9       0.96      0.95      0.95      1800\n\n    accuracy                           0.89     18000\n   macro avg       0.89      0.89      0.89     18000\nweighted avg       0.89      0.89      0.89     18000"},{"metadata":{},"cell_type":"markdown","source":"3.1.4. Random Forest with PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# rf = RandomForestClassifier(random_state=42)\n# rf.fit(X_train_reduced, y_train)\n\n# predictions_rf = rf.predict(X_test_reduced)\n\n# class_report_rf = classification_report(y_test, predictions_rf)\n# print(\"Random Forest reduced classification report:\\n\", class_report_rf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest reduced classification report:\n               precision    recall  f1-score   support\n\n           0       0.78      0.85      0.81      1800\n           1       0.99      0.96      0.98      1800\n           2       0.78      0.79      0.79      1800\n           3       0.85      0.89      0.87      1800\n           4       0.75      0.82      0.78      1800\n           5       0.93      0.91      0.92      1800\n           6       0.73      0.55      0.63      1800\n           7       0.92      0.91      0.91      1800\n           8       0.92      0.96      0.94      1800\n           9       0.92      0.95      0.93      1800\n\n    accuracy                           0.86     18000\n   macro avg       0.86      0.86      0.86     18000\nweighted avg       0.86      0.86      0.86     18000"},{"metadata":{},"cell_type":"markdown","source":"3.2. K-Means"},{"metadata":{},"cell_type":"markdown","source":"3.2.1. Log Reg with K-Means"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline = Pipeline([(\"kmeans\", KMeans(n_clusters=150)), (\"log_reg\", LogisticRegression(max_iter=1000000, n_jobs=-1))])\npipeline.fit(X_train_scaled, y_train)\n\npipeline.score(X_test_scaled, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"n_clusters=50, 0.8223333333333334\n\nn_clusters=100, 0.8430555555555556\n\nn_clusters=150, 0.8523888888888889"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''Takes way to much time to compute'''\n\n# pipeline_logreg_kmeans = Pipeline([(\"kmeans\", KMeans(n_clusters=50)), (\"log_reg\", LogisticRegression(max_iter=1000000, n_jobs=-1))])\n\n# param_grid_logreg_kmeans = dict(kmeans__n_clusters=range(2, 100))\n# grid_logreg_kmeans = GridSearchCV(pipeline_logreg_kmeans, param_grid_logreg_kmeans, cv=10, verbose=2)\n# grid_logreg_kmeans.fit(X_train_scaled, y_train)\n\n# print(\"SVC - Best params:\\n\", grid_logreg_kmeans.best_params_)\n# print(\"SVC - Best cross-validation score:\\n\", grid_logreg_kmeans.best_score_)\n# print(\"SVC - Test score:\\n\", grid_svc.score(X_test_scaled, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3.2.2. KNN with K-Means"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_knn = Pipeline([(\"kmeans\", KMeans(n_clusters=100)), (\"knn\", KNeighborsClassifier(n_neighbors=7, n_jobs=-1))])\npipeline_knn.fit(X_train_scaled, y_train)\n\npipeline_knn.score(X_test_scaled, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0.7940555555555555"},{"metadata":{},"cell_type":"markdown","source":"3.2.3. SVC with K-Means"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_svc = Pipeline([(\"kmeans\", KMeans(n_clusters=100)), (\"svc\", SVC(C=1))])\npipeline_svc.fit(X_train_scaled, y_train)\n\npipeline_svc.score(X_test_scaled, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0.7764444444444445"},{"metadata":{},"cell_type":"markdown","source":"3.2.4. Random Forest with K-Mean"},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_rf = Pipeline([(\"kmeans\", KMeans(n_clusters=100)), (\"rf\", RandomForestClassifier(random_state=42, n_jobs=-1))])\npipeline_rf.fit(X_train, y_train)\n\npipeline_rf.score(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"n_clusters=50, 0.8048333333333333\n\nn_clusters=100, "},{"metadata":{},"cell_type":"markdown","source":"3.3. DBSCAN"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''DBSCAN finds no clusters at all; tryied many hyperparameters. No results!'''\n\n# dbscan = DBSCAN(eps=0.05, min_samples=5)\n# dbscan.fit(X_train_scaled)\n# print(\"dbscan labels:\\n\",dbscan.labels_)\n# print(\"lenght core sample indices:\\n\",len(dbscan.core_sample_indices_))\n# print(\"core smape indices:\\n\", dbscan.core_sample_indices_)\n# print(\"components:\\n\", dbscan.components_)\n\n# knn_dbscan = KNeighborsClassifier(n_neighbors=50)\n# knn_dbscan.fit(dbscan.components_, dbscan.labels_[dbscan.core_sample_indices_])\n\n# knn_dbscan.predict(X_test_scaled)\n\n# plt.figure(figsize=(15, 15))\n# plot_decision_boundaries(knn_dbscan, X_train_scaled, show_centroids=False)\n# plt.scatter(X_test_scaled[:, 0], X_test_scaled[:, 1], c=\"b\", marker=\"+\", s=200, zorder=10)\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PART 4**\n\nUsing t-SNE to visualize the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"def fashion_scatter(x, colors):\n    # choose a color palette with seaborn.\n    num_classes = len(np.unique(colors))\n    palette = np.array(sns.color_palette(\"hls\", num_classes))\n\n    # create a scatter plot.\n    f = plt.figure(figsize=(12, 12))\n    ax = plt.subplot(aspect='equal')\n    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40, c=palette[colors.astype(np.int)])\n    plt.xlim(-25, 25)\n    plt.ylim(-25, 25)\n    ax.axis('off')\n    ax.axis('tight')\n\n    # add the labels for each digit corresponding to the label\n    txts = []\n\n    for i in range(num_classes):\n        \n        # Position of each label at median of data points.\n\n        xtext, ytext = np.median(x[colors == i, :], axis=0)\n        txt = ax.text(xtext, ytext, str(i), fontsize=24)\n        txt.set_path_effects([\n            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n            PathEffects.Normal()])\n        txts.append(txt)\n\n    return f, ax, sc, txts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"t-SNE reduction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# tsne = TSNE(random_state=42)\n# # use fit_transform instead of fit, as TSNE has no transform method\n# fashion_tsne = tsne.fit_transform(X_train_scaled)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"t-SNE visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# fashion_scatter(fashion_tsne, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"t-SNE reduction with pre-reduction with PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"tsne_pca = TSNE(random_state=42)\nfashion_tsne_pca = tsne_pca.fit_transform(X_train_reduced)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"t-SNE with PCA reduction visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"fashion_scatter(fashion_tsne_pca, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PART 5**\n\nFine tuning with gridsearch for best models. In my opinion the best are SVC on PCA reduced data as well as Random Forest on raw data."},{"metadata":{},"cell_type":"markdown","source":"5.1. SVC on scaled data"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_class = SVC()\n\nparam_grid_svc = [{'gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n                  'C': [0.001, 0.01, 0.1, 1, 10, 100]\n                  }]\n\ngrid_svc = GridSearchCV(svc_class, param_grid_svc, cv=10)\ngrid_svc.fit(X_train_reduced, y_train)\n\nprint(\"SVC - Best params:\\n\", grid_svc.best_params_)\nprint(\"SVC - Best cross-validation score:\\n\", grid_svc.best_score_)\nprint(\"SVC - Test score:\\n\", grid_svc.score(X_test_reduced, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5.1.1. SVC Error analysis"},{"metadata":{},"cell_type":"markdown","source":"SVC with best params from GridsearchCV:"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_best = SVC()\nsvc_train_prediction = cross_val_predict(svc_best, X_train_reduced, y_train, cv=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SVC - Confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_mx_svc = confusion_matrix(y_train, svc_train_prediction)\nconf_mx_svc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SVC - Visualization of confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.matshow(conf_mx_svc, cmap=plt.cm.gray)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SVC - Let´s divide each value in the confusion matrix by the number of images in the corresponding class to compare\nerror rates instead of absolute number of errors."},{"metadata":{"trusted":true},"cell_type":"code","source":"row_sums_svc = conf_mx_svc.sum(axis=1, keepdims=True)\nnorm_conf_mx_svc = conf_mx_svc / row_sums_svc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SVC - Now let’s fill the diagonal with zeros to keep only the errors, and let’s plot the result:"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.fill_diagonal(norm_conf_mx_svc, 0)\nplt.matshow(norm_conf_mx_svc, cmap=plt.cm.gray)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SVC - ROC AUC Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_scores_svc = svc_best.predict_proba(X_test_reduced)\ny_scores_svc = y_scores[:,1]\n\nr_a_score_svc = roc_auc_score_svc(y_test, y_scores_svc)\nprint(\"SVC best - ROC-AUC-Score:\", r_a_score_svc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5.2. Random Forest on raw data"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\n\nparam_grid_rf = [{'max_features': [2, 3, 4, 5],\n               'max_depth': [3, 4, 5, 6, 7],\n               'n_estimators': [10, 50, 100, 200, 500]\n              }]\n\ngrid_rf = GridSearchCV(rf, param_grid_rf, cv=10)\ngrid_rf.fit(X_train, y_train)\nprint(\"RF - Best params:\\n\", grid_rf.best_params_)\nprint(\"RF - Best cross-validation score:\\n\", grid_rf.best_score_)\nprint(\"RF - Test score:\\n\", grid_rf.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RF - Best params:\n {'max_depth': 7, 'max_features': 5, 'n_estimators': 500}\n\nRF - Best cross-validation score:\n 0.8017142857142858\n\nRF - Test score:\n 0.8006111111111112"},{"metadata":{},"cell_type":"markdown","source":"5.2.1. RF Error analysis"},{"metadata":{},"cell_type":"markdown","source":"RF - Confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_best = RandomForestClassifier(max_depth=7, max_features=5)\nrf_train_prediction = cross_val_predict(rf_best, X_train, y_train, cv=10)\nconf_mx_rf = confusion_matrix(y_train, rf_train_prediction)\nconf_mx_rf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RF - Visualization of confusion matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.matshow(conf_mx_rf, cmap=plt.cm.gray)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RF - Error rates"},{"metadata":{"trusted":true},"cell_type":"code","source":"row_sums = conf_mx_rf.sum(axis=1, keepdims=True)\nnorm_conf_mx_rf = conf_mx_rf / row_sums","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RF - Visualization of error rates"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.fill_diagonal(norm_conf_mx_rf, 0)\nplt.matshow(norm_conf_mx_rf, cmap=plt.cm.gray)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RF - ROC AUC Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_best.fit(X_train, y_train)\nprediction_rf = rf_best.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_scores_rf = rf_best.predict_proba(X_test)\n\nr_a_score_rf = roc_auc_score(y_test, y_scores_rf, multi_class='ovo')\nprint(\"RF best - ROC-AUC-Score:\", r_a_score_rf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RF best - ROC-AUC-Score: 0.9772588648834019"},{"metadata":{"trusted":true},"cell_type":"code","source":"r_a_score_rf_ovr = roc_auc_score(y_test, y_scores_rf, multi_class='ovr')\nprint(\"RF best - ROC-AUC-Score OVR:\", r_a_score_rf_ovr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"RF best - ROC-AUC-Score OVR: 0.977258864883402"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}